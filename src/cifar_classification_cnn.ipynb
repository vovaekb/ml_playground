{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar_classification_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vovaekb/ml_playground/blob/master/src/cifar_classification_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ES99DuGCCT50",
        "colab_type": "code",
        "outputId": "7d0bb2a6-a43d-4167-a9d5-9cbed4bc9c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras_sequential_ascii"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_sequential_ascii in /usr/local/lib/python2.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python2.7/dist-packages (from keras_sequential_ascii) (2.2.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from keras->keras_sequential_ascii) (1.0.7)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python2.7/dist-packages (from keras->keras_sequential_ascii) (1.14.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from keras->keras_sequential_ascii) (1.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras->keras_sequential_ascii) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from keras->keras_sequential_ascii) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages (from keras->keras_sequential_ascii) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from keras->keras_sequential_ascii) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1etdDbMZ4xNG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Train a simple deep CNN on the CIFAR10 small images dataset\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.constraints import maxnorm\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Flatten, Dropout, Activation\n",
        "from keras.utils import np_utils\n",
        "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
        "from keras import backend as K\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5kTiCSN53F5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example: https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py\n",
        "\n",
        "Tutorial: https://blog.plon.io/tutorials/cifar-10-classification-using-keras-tutorial/"
      ]
    },
    {
      "metadata": {
        "id": "35HDXODVh0iK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Declare variables\n",
        "batch_size = 32\n",
        "\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "data_augmentation = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YQ5DNrmERR3x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define image dimensionalty ordering\n",
        "# For TensorFlow 0.10 would use \"tf\", 0.11 would use \"th\"\n",
        "if K.backend() == 'tensorflow':\n",
        "  K.set_image_dim_ordering('tf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSPD7lxL5hJS",
        "colab_type": "code",
        "outputId": "1571d6d0-8963-4bc8-de26-afa0eb3553e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OHWb1hyq6h5_",
        "colab_type": "code",
        "outputId": "30730e85-113c-43a2-cbe3-f08cbc305626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(y_train[0,])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mhzdSKtXk4BT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Print 10 random images from each class\n",
        "'''\n",
        "fig = plt.figure(figsize=(8, 3))\n",
        "for i in range(num_classes):\n",
        "  ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "  idx = np.where(x_train[:]==i)[0]\n",
        "  features_idx = x_train[idx,::]\n",
        "  img_num = np.random.randint(features_idx.shape[0])\n",
        "  im = np.transpose(features_idx[img_num,::],(1,2,0))\n",
        "  ax.set_titles(class_names[i])\n",
        "  plt.imshow(im)\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3zbxdddk4F7",
        "colab_type": "code",
        "outputId": "a4f7d7f2-7aaa-4d19-d9b5-2005d1b42014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        }
      },
      "cell_type": "code",
      "source": [
        "# Convert and pre-processing\n",
        "# Question: why sometimes one uses numpy reshape() method to reshape the data samples to (num_samples, 1024)?\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "print(x_train[0,:40])\n",
        "print(y_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.23137255 0.24313726 0.24705882]\n",
            "  [0.16862746 0.18039216 0.1764706 ]\n",
            "  [0.19607843 0.1882353  0.16862746]\n",
            "  ...\n",
            "  [0.61960787 0.5176471  0.42352942]\n",
            "  [0.59607846 0.49019608 0.4       ]\n",
            "  [0.5803922  0.4862745  0.40392157]]\n",
            "\n",
            " [[0.0627451  0.07843138 0.07843138]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.07058824 0.03137255 0.        ]\n",
            "  ...\n",
            "  [0.48235294 0.34509805 0.21568628]\n",
            "  [0.46666667 0.3254902  0.19607843]\n",
            "  [0.47843137 0.34117648 0.22352941]]\n",
            "\n",
            " [[0.09803922 0.09411765 0.08235294]\n",
            "  [0.0627451  0.02745098 0.        ]\n",
            "  [0.19215687 0.10588235 0.03137255]\n",
            "  ...\n",
            "  [0.4627451  0.32941177 0.19607843]\n",
            "  [0.47058824 0.32941177 0.19607843]\n",
            "  [0.42745098 0.28627452 0.16470589]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.8156863  0.6666667  0.3764706 ]\n",
            "  [0.7882353  0.6        0.13333334]\n",
            "  [0.7764706  0.6313726  0.10196079]\n",
            "  ...\n",
            "  [0.627451   0.52156866 0.27450982]\n",
            "  [0.21960784 0.12156863 0.02745098]\n",
            "  [0.20784314 0.13333334 0.07843138]]\n",
            "\n",
            " [[0.7058824  0.54509807 0.3764706 ]\n",
            "  [0.6784314  0.48235294 0.16470589]\n",
            "  [0.7294118  0.5647059  0.11764706]\n",
            "  ...\n",
            "  [0.72156864 0.5803922  0.36862746]\n",
            "  [0.38039216 0.24313726 0.13333334]\n",
            "  [0.3254902  0.20784314 0.13333334]]\n",
            "\n",
            " [[0.69411767 0.5647059  0.45490196]\n",
            "  [0.65882355 0.5058824  0.36862746]\n",
            "  [0.7019608  0.5568628  0.34117648]\n",
            "  ...\n",
            "  [0.84705883 0.72156864 0.54901963]\n",
            "  [0.5921569  0.4627451  0.32941177]\n",
            "  [0.48235294 0.36078432 0.28235295]]]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ueOV0UAe8rlZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Add data augmentation: https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py\n",
        "# Interesting example: https://medium.com/@ksusorokina/image-classification-with-convolutional-neural-networks-496815db12a8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_3OmS66FKUt",
        "colab_type": "code",
        "outputId": "abdf7662-783c-41c3-fdfd-6689c13b56f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1344
        }
      },
      "cell_type": "code",
      "source": [
        "# Define network architecture\n",
        "# 4-layer network\n",
        "def four_layer_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  sgd = SGD(lr=0.1) #, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  \n",
        "  # Train model\n",
        "  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# Source: https://colab.research.google.com/drive/1Q7CGlx0lQa8YxwOsLzsPdMMITAjHHENE#scrollTo=XrisZPa4D1hk\n",
        "def one_layer_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3,3), input_shape=x_train.shape[1:]))\n",
        "  model.add(Conv2D(64, (3,3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "cnn_n = four_layer_model()\n",
        "#cnn_n = one_layer_model()\n",
        "cnn_n.summary()\n",
        "\n",
        "start = time.time()\n",
        "if not data_augmentation:\n",
        "  print('Not using data augmentation.')\n",
        "  cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
        "else:\n",
        "  print('Using real-time data augmentation.')\n",
        "  # This will do preprocessing and realtime data augmentation:\n",
        "  datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest',\n",
        "      validation_split=0.0\n",
        "  )\n",
        "  \n",
        "  # Compute quantities required for feature-wise normalization\n",
        "  # (std, mean, and principal components if ZCA whitening is applied).\n",
        "  datagen.fit(x_train)\n",
        "  \n",
        "  # Fit the model on the batches generated by datagen.flow().\n",
        "  cnn = cnn_n.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                        batch_size=batch_size),\n",
        "                           epochs=epochs, \n",
        "                           validation_data=(x_test, y_test),\n",
        "                           workers=2)\n",
        "\n",
        "end = time.time()  \n",
        "print(end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6b64ef929572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m                            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                            workers=2)\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             raise ValueError('`steps_per_epoch=None` is only valid for a'\n\u001b[0m\u001b[1;32m     56\u001b[0m                              \u001b[0;34m' generator based on the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                              \u001b[0;34m'`keras.utils.Sequence`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `steps_per_epoch=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the `keras.utils.Sequence` class."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "m4edvpgBoTTT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data augmentation\n",
        "**Without Data augmentation**\n",
        "loss: 0.9093 - acc: 0.6823 - val_loss: 0.9387 - val_acc: 0.6720\n",
        "Accuracy: 67.20%, loss: 0.94\n",
        "\n",
        "**With Data augmentation**\n",
        "loss: 1.5397 - acc: 0.4432 - val_loss: 1.2537 - val_acc: 0.5486\n",
        "Accuracy: 54.86%, loss: 1.25\n"
      ]
    },
    {
      "metadata": {
        "id": "7XjUk3pAbWSe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualizing model structure\n",
        "sequential_model_to_ascii_printout(cnn_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TsGbRMXTm73I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot training and testing process\n",
        "plt.figure(0)\n",
        "plt.plot(cnn.history['acc'], 'r')\n",
        "plt.plot(cnn.history['val_acc'], 'g')\n",
        "plt.xticks(np.arange(0, 101, 2.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num. of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "plt.legend(['train', 'validation'])\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(cnn.history['loss'], 'r')\n",
        "plt.plot(cnn.history['val_loss'], 'g')\n",
        "plt.xticks(np.arange(0, 101, 2.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num. of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train', 'validation'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7kXNbmAvzDbK",
        "colab_type": "code",
        "outputId": "055b5523-e97c-43d9-efeb-f745ed24ab1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Final testing accuracy\n",
        "(loss, acc) = cnn_n.evaluate(x_test, y_test)\n",
        "print('Accuracy: %.2f%%, loss: %.2f' % (acc*100, loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 156us/step\n",
            "Accuracy: 54.86%, loss: 1.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AZ9mQTv90aKu",
        "colab_type": "code",
        "outputId": "64d4ca47-3cb7-4f33-ea2c-8d53b274d947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model_name = \"simple_cnn\"\n",
        "cnn_n.save(model_name)\n",
        "print(\"Model %s has been successfully saved\" % model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model simple_cnn has been successfully saved\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}